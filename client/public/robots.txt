# robots.txt for Neumont Virtual Campus Web App

# Allow all search engines to crawl the site
User-agent: *
Allow: /

# Sitemap location
Sitemap: https://neuvirtualcampus.neumont.edu/sitemap.xml

# Crawl delay to be respectful of server resources
Crawl-delay: 1

# Disallow crawling of WebSocket endpoints and API routes
Disallow: /ws
Disallow: /api/
